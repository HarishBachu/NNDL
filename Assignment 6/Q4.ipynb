{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ac7e701b-6e00-4bed-8888-7660e0cfa53d",
    "_uuid": "1845c40c-4f5e-4587-abc6-cffc41e0e74e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-11-09T05:18:12.439820Z",
     "iopub.status.busy": "2021-11-09T05:18:12.439447Z",
     "iopub.status.idle": "2021-11-09T05:18:21.891016Z",
     "shell.execute_reply": "2021-11-09T05:18:21.890181Z",
     "shell.execute_reply.started": "2021-11-09T05:18:12.439739Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#reading images and resizing them into the same shape\n",
    "root='../input/semantic-segmentation-of-aerial-imagery/Semantic segmentation dataset/'\n",
    "imagearray=[]\n",
    "\n",
    "for path,subs,files in os.walk(root):\n",
    "    dirname=path.split(os.path.sep)[-1]\n",
    "    if dirname==\"images\":\n",
    "        images=os.listdir(path)\n",
    "        for i,name in enumerate(images):\n",
    "            if name.endswith(\".jpg\"):\n",
    "\n",
    "                image=cv2.imread(path+\"/\"+name,1)\n",
    "                image=cv2.resize(image,(256,256))\n",
    "                image=np.array(image)\n",
    "                imagearray.append(image)\n",
    "\n",
    "maskarray=[]\n",
    "\n",
    "for path,subs,files in os.walk(root):\n",
    "    dirname=path.split(os.path.sep)[-1]\n",
    "    if dirname==\"masks\":\n",
    "        masks=os.listdir(path)\n",
    "        for i,M_name in enumerate(masks):\n",
    "            if M_name.endswith(\".png\"):\n",
    "\n",
    "                mask =cv2.imread(path+\"/\"+M_name,1)\n",
    "                mask =cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)\n",
    "                mask =cv2.resize(mask,(256,256))\n",
    "                mask =np.array(mask)\n",
    "                maskarray.append(mask)\n",
    "\n",
    "imagedata = np.array(imagearray)\n",
    "maskdata =  np.array(maskarray)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:18:21.892863Z",
     "iopub.status.busy": "2021-11-09T05:18:21.892532Z",
     "iopub.status.idle": "2021-11-09T05:18:22.739864Z",
     "shell.execute_reply": "2021-11-09T05:18:22.739030Z",
     "shell.execute_reply.started": "2021-11-09T05:18:21.892827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Building=np.array([60,16,152])\n",
    "Land=np.array([132,41,246])\n",
    "road=np.array([110,193,228])\n",
    "Vegetation=np.array([254,221,58])\n",
    "water=np.array([226,169,41])\n",
    "Unlabeled =np.array([155,155,155])\n",
    "\n",
    "label = maskdata\n",
    "\n",
    "def flatLabels(label):\n",
    "\n",
    "    label_seg = np.zeros(label.shape, dtype=np.uint8)\n",
    "    label_seg[np.all(label == Building, axis=-1)] = 0\n",
    "    label_seg[np.all(label == Land, axis=-1)] = 1\n",
    "    label_seg[np.all(label == road, axis=-1)] = 2\n",
    "    label_seg[np.all(label == Vegetation, axis=-1)] = 3\n",
    "    label_seg[np.all(label == water, axis=-1)] = 4\n",
    "    label_seg[np.all(label == Unlabeled, axis=-1)] = 5\n",
    "\n",
    "    label_seg = label_seg[:, :, 0]  # Just take the first channel, no need for all 3 channels\n",
    "\n",
    "    return label_seg\n",
    "\n",
    "labels = []\n",
    "for i in range(maskdata.shape[0]):\n",
    "    label = flatLabels(maskdata[i])\n",
    "    labels.append(label)\n",
    "\n",
    "labels = np.array(labels)\n",
    "labels = np.expand_dims(labels, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:18:22.742019Z",
     "iopub.status.busy": "2021-11-09T05:18:22.741690Z",
     "iopub.status.idle": "2021-11-09T05:18:31.749966Z",
     "shell.execute_reply": "2021-11-09T05:18:31.749112Z",
     "shell.execute_reply.started": "2021-11-09T05:18:22.741985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#one hot encoding to_categorical\n",
    "\n",
    "n_classes = len(np.unique(labels))\n",
    "from keras.utils import to_categorical\n",
    "labels_cat = to_categorical(labels, num_classes=n_classes)\n",
    "\n",
    "!pip install segmentation-models==1.0.1\n",
    "import keras\n",
    "from keras.utils import generic_utils\n",
    "import segmentation_models as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(imagedata, labels_cat, test_size = 0.20)\n",
    "\n",
    "#those weights are optional, (automatically will be set all weights to 1)\n",
    "\n",
    "weights = [0.155, 0.155, 0.155, 0.155, 0.155, 0.155]\n",
    "\n",
    "dice_loss=sm.losses.DiceLoss(class_weights=weights)\n",
    "focal=sm.losses.CategoricalFocalLoss()\n",
    "total=dice_loss+(1*focal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:18:31.751857Z",
     "iopub.status.busy": "2021-11-09T05:18:31.751518Z",
     "iopub.status.idle": "2021-11-09T05:18:31.773836Z",
     "shell.execute_reply": "2021-11-09T05:18:31.772499Z",
     "shell.execute_reply.started": "2021-11-09T05:18:31.751821Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, \\\n",
    "    Dropout, Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "def unet(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = inputs\n",
    "\n",
    "    # begin with contraction part\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.2)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.2)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.2)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.2)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "    # define output layer\n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:22:22.265718Z",
     "iopub.status.busy": "2021-11-09T05:22:22.265354Z",
     "iopub.status.idle": "2021-11-09T05:22:22.272420Z",
     "shell.execute_reply": "2021-11-09T05:22:22.271569Z",
     "shell.execute_reply.started": "2021-11-09T05:22:22.265668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def focal_loss(alpha=0.001, gamma=2):\n",
    "  def focal_loss_with_logits(logits, targets, alpha, gamma, y_pred):\n",
    "    targets = tf.cast(targets, tf.float32)\n",
    "    weight_a = alpha * (1 - y_pred) ** gamma * targets\n",
    "    weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n",
    "    \n",
    "    return (tf.math.log1p(tf.exp(-tf.abs(logits))) + tf.nn.relu(-logits)) * (weight_a + weight_b) + logits * weight_b \n",
    "\n",
    "  def loss(y_true, logits):\n",
    "    y_pred = tf.math.sigmoid(logits)\n",
    "    loss = focal_loss_with_logits(logits=logits, targets=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:22:47.853956Z",
     "iopub.status.busy": "2021-11-09T05:22:47.853625Z",
     "iopub.status.idle": "2021-11-09T05:23:11.337022Z",
     "shell.execute_reply": "2021-11-09T05:23:11.336226Z",
     "shell.execute_reply.started": "2021-11-09T05:22:47.853926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMG_HEIGHT = X_train.shape[1]\n",
    "IMG_WIDTH  = X_train.shape[2]\n",
    "IMG_CHANNELS = X_train.shape[3]\n",
    "\n",
    "\n",
    "\n",
    "metrics=['accuracy', jacard_coef]\n",
    "\n",
    "def get_model():\n",
    "    return unet(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizer='adam', loss=focal_loss(), metrics=metrics)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history1 = model.fit(X_train, y_train,\n",
    "                    batch_size = 16,\n",
    "                    verbose=1,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:23:52.050346Z",
     "iopub.status.busy": "2021-11-09T05:23:52.049993Z",
     "iopub.status.idle": "2021-11-09T05:23:52.343912Z",
     "shell.execute_reply": "2021-11-09T05:23:52.343089Z",
     "shell.execute_reply.started": "2021-11-09T05:23:52.050311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "history = history1\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training + validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['jacard_coef']\n",
    "val_acc = history.history['val_jacard_coef']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training IoU')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation IoU')\n",
    "plt.title('Training and validation IoU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IoU')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# I would like to thank Dr. Sreenivas Bhattiprolu for giving me so much inspiration for this analysis, I tried to apply what I learned from his channel to this notebook. check his wonderful youtube channel:  https://www.youtube.com/channel/UC34rW-HtPJulxr5wp2Xa04w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
